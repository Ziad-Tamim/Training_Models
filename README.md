# Chapter 4: Training Models

**Hand-On Machine Learning Book**  
**Author:** Ziad Tamim  
**Date:** 29/04/2025

## Overview

In Chapter 4 we lift the lid on common “black-box” learning algorithms and explore the methods that make them tick:

- **Linear Regression**  
  - Closed-form solution via the Normal Equation  
  - Iterative optimization with Gradient Descent (batch, mini-batch, stochastic)  
- **Polynomial Regression**  
  - Nonlinear feature expansion  
  - Overfitting detection with learning curves  
  - Regularization techniques (Ridge, Lasso, Elastic Net)  
- **Early Stopping**  
  - Simple yet powerful regularization by halting training at the validation-error minimum  
- **Classification Models**  
  - Logistic Regression for binary outcomes  
  - Softmax Regression for multiclass problems  

By understanding these training algorithms and hyperparameters, you’ll be equipped to choose the right model, debug training issues, and prepare for the neural-network techniques in Part II.  